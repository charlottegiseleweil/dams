{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing dam data for darknet format:\n",
    "\n",
    "This script has two inputs:\n",
    "    - not_a_dam_images.zip\n",
    "    - dam_images.zip\n",
    "and two outputs (directories)\n",
    "    - images\n",
    "    - labels\n",
    "\n",
    "The input zip files should be in the same directory\n",
    "\n",
    "Each output image file will correspond to a label file, which is in darknet format (class, center x, center y, width, height)\n",
    "\n",
    "x y w h are all normalized (between 0 and 1) relative to image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'gdal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f788f2f571ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'gdal'"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import zipfile as zf\n",
    "import json\n",
    "import numpy as np\n",
    "import shapely\n",
    "import random\n",
    "from matplotlib import image as mpimg\n",
    "\n",
    "import gdal\n",
    "\n",
    "import requests\n",
    "\n",
    "import logging\n",
    "LOGGER = logging.getLogger()\n",
    "LOGGER.setLevel(logging.DEBUG)\n",
    "LOGGER.info(\"Logger in INFO mode\")\n",
    "LOGGER.debug(\"Logger in DEBUG mode\")\n",
    "LOGGER.debug(\"Logger in DEBUG mode\")\n",
    "\n",
    "REQUEST_TIMEOUT = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Paths\n",
    "\n",
    "path_to_charlie_root = \"../../..\"\n",
    "NOT_A_DAM_IMAGE_DIR = os.path.join(path_to_charlie_root,\"data/imagery-6-7-2019/not_a_dam_images\")\n",
    "DAM_IMAGE_DIR = os.path.join(path_to_charlie_root,\"data/imagery-6-7-2019/dam_images\")\n",
    "\n",
    "TM_WORLD_BORDERS_URL = 'https://storage.googleapis.com/ecoshard-root/ipbes/TM_WORLD_BORDERS_SIMPL-0.3_md5_15057f7b17752048f9bd2e2e607fe99c.zip'\n",
    "\n",
    "if not os.path.exists(NOT_A_DAM_IMAGE_DIR):\n",
    "    raise ValueError(\"can't find %s'\" % NOT_A_DAM_IMAGE_DIR)\n",
    "if not os.path.exists(DAM_IMAGE_DIR):\n",
    "    raise ValueError(\"can't find %s'\" % DAM_IMAGE_DIR)\n",
    "    \n",
    "OUTPUTS_DIR = os.path.join(path_to_charlie_root,\"data/YOLOready_imagery_6-7_made_6-20\")\n",
    "WORKSPACE_DIR = OUTPUTS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run just one of the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subsets of data inputs - for faster development purposes\n",
    "\n",
    "dam_file_list = [os.path.join(DAM_IMAGE_DIR, f)\n",
    "                 for f in os.listdir(DAM_IMAGE_DIR) if f.endswith('5140_clipped.png')]\n",
    "not_a_dam_file_list = [os.path.join(NOT_A_DAM_IMAGE_DIR, f)\n",
    "                       for f in os.listdir(NOT_A_DAM_IMAGE_DIR) if f.endswith('362_not_a_dam.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full dataset \n",
    "\n",
    "dam_file_list = [os.path.join(DAM_IMAGE_DIR, f)\n",
    "                 for f in os.listdir(DAM_IMAGE_DIR) if f.endswith('clipped.png')]\n",
    "not_a_dam_file_list = [os.path.join(NOT_A_DAM_IMAGE_DIR, f)\n",
    "                       for f in os.listdir(NOT_A_DAM_IMAGE_DIR) if f.endswith('not_a_dam.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dam_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_a_dam_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do run this one to merge dam_list and not_a_dam_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images_file_list = dam_file_list+not_a_dam_file_list\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(all_images_file_list)\n",
    "\n",
    "len(all_images_file_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_set_portion = .2\n",
    "validation_set_portion = .15\n",
    "Dams_per_round = 5#1000 # = max_dams_per_record "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get South Africa geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LOGGER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-53c655c204fc>\u001b[0m in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, target_file_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREQUEST_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-53c655c204fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         WORKSPACE_DIR, 'world_borders', os.path.basename(TM_WORLD_BORDERS_URL))\n\u001b[1;32m     31\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtm_world_borders_zip_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdownload_url_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTM_WORLD_BORDERS_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtm_world_borders_zip_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtm_world_borders_zip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORKSPACE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-53c655c204fc>\u001b[0m in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, target_file_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'download of {url} to {target_file_path} failed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# mods from LOGGER.exception(f'download of {url} to {target_file_path} failed')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LOGGER' is not defined"
     ]
    }
   ],
   "source": [
    "def download_url_to_file(url, target_file_path):\n",
    "    \"\"\"Use requests to download a file.\n",
    "\n",
    "    Parameters:\n",
    "        url (string): url to file.\n",
    "        target_file_path (string): local path to download the file.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, stream=True, timeout=REQUEST_TIMEOUT)\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(target_file_path))\n",
    "        except OSError:\n",
    "            pass\n",
    "        with open(target_file_path, 'wb') as target_file:\n",
    "            shutil.copyfileobj(response.raw, target_file)\n",
    "        del response\n",
    "    except:\n",
    "        LOGGER.exception('download of {url} to {target_file_path} failed')\n",
    "        # mods from LOGGER.exception(f'download of {url} to {target_file_path} failed')\n",
    "        raise\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "tm_world_borders_zip_path = os.path.join(\n",
    "        WORKSPACE_DIR, 'world_borders', os.path.basename(TM_WORLD_BORDERS_URL))\n",
    "if not os.path.exists(tm_world_borders_zip_path):\n",
    "    download_url_to_file(TM_WORLD_BORDERS_URL, tm_world_borders_zip_path)\n",
    "    with zipfile.ZipFile(tm_world_borders_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(WORKSPACE_DIR)\n",
    "\n",
    "tm_world_borders_vector_path = os.path.join(\n",
    "    WORKSPACE_DIR, 'TM_WORLD_BORDERS-0.3.shp')\n",
    "#tm_world_borders_vector = gdal.Open(ogr.Open(tm_world_borders_vector_path)) # Changed OpenEx to Open.\n",
    "    #tm_world_borders_vector_path,ogr.Open(path))#, gdal.OF_VECTOR)\n",
    "tm_world_borders_vector = ogr.Open(tm_world_borders_vector_path)\n",
    "tm_world_borders_layer = tm_world_borders_vector.GetLayer()\n",
    "for border_feature in tm_world_borders_layer:\n",
    "    if border_feature.GetField('NAME') == 'South Africa':\n",
    "        sa_geom = border_feature.GetGeometryRef()\n",
    "        sa_geom_prep = shapely.prepared.prep(\n",
    "            shapely.wkb.loads(sa_geom.ExportToWkb()))\n",
    "        break\n",
    "LOGGER.debug(sa_geom_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Make YOLO-ready data !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils: Function to make YOLO_ready data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images_labels(images_file_list, iteration): \n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    Takes in folder of dam pngs, folder of bounding box json files\n",
    "    Normalizes json data to darknet format (center x, center y, bbox width, bbox height)\n",
    "    Creates new directories in darknet format\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print('Starting to make YOLO-ready data, round %d' % iteration)\n",
    "    \n",
    "    random.seed(iteration)\n",
    "    random_numbers_list = [random.random() for x in range(0, len(images_file_list))]\n",
    "    random_number_iterator = 0\n",
    "    \n",
    "    for image_path in images_file_list:\n",
    "        \n",
    "        # read in image\n",
    "        img = mpimg.imread(image_path)\n",
    "\n",
    "        # get width and height\n",
    "        img_w = img.shape[0]\n",
    "        img_h = img.shape[1]\n",
    "\n",
    "        # get matching bounding box json file\n",
    "        json_path = image_path.replace('.png', '.json')\n",
    "        if not os.path.exists(json_filepath):\n",
    "            raise NameError(\"can't find bbox for %s\" % json_path)\n",
    "            \n",
    "        # read json bounding box coordinates\n",
    "        with open(json_path, 'r') as json_file: \n",
    "            image_metadata = json.load(json_file)\n",
    "        \n",
    "        # normalize to x-center, y-center, width, and height of bbox\n",
    "        coords = image_metadata['pixel_bounding_box']\n",
    "        avg_x = (coords[2] + coords[0]) / (2 * img_w)\n",
    "        avg_y = (coords[1] + coords[3]) / (2 * img_h)\n",
    "        nrm_w = (coords[2] - coords[0]) / img_w\n",
    "        nrm_h = (coords[1] - coords[3]) / img_h\n",
    "        nrm_xywh = np.array([avg_x, avg_y, nrm_w, nrm_h])\n",
    "\n",
    "        # Define new label in YOLO format\n",
    "        if 'not_a_dam' in image_path:\n",
    "            dam_type = 'not_a_dam'\n",
    "            label_str = ''\n",
    "        else:\n",
    "            dam_type = 'dam'\n",
    "            label_str = '0 ' + str('%.6f'%nrm_xywh[0]) + ' ' + str('%.6f'%nrm_xywh[1]) + ' ' + str('%.6f'%nrm_xywh[2]) + ' ' + str('%.6f'%nrm_xywh[3])\n",
    "\n",
    "            \n",
    "            \n",
    "        # - - -   - - -   - - -   \n",
    "        # Choose whether this record will go to training or validation (=dev) set \n",
    "        try:\n",
    "            centroid = image_metadata['lng_lat_centroid']\n",
    "        except NameError:\n",
    "            raise Exception(\"Missing lat/lon for in file\", json_path)\n",
    "            \n",
    "            \n",
    "        random_number = random_numbers_list[random_number_iterator]\n",
    "        random_number_iterator+=1\n",
    "        \n",
    "        if sa_geom_prep.contains(shapely.geometry.Point(centroid[0], centroid[1])): # both for dams & not_a_dams\n",
    "            writer = 'southaf_set'\n",
    "            log = southaf_log\n",
    "        elif random_number < holdout_set_portion:\n",
    "            writer = 'test_set'\n",
    "            log = test_log\n",
    "        elif random_number > (1-validation_set_portion):\n",
    "            writer = 'validation_set'\n",
    "            log = validation_log\n",
    "        else:\n",
    "            writer = 'training_set'\n",
    "            log = training_log\n",
    "            \n",
    "        # Write the file in the corresponding set\n",
    "        \n",
    "        ## Write image here:\n",
    "        filename = \n",
    "            \n",
    "        newimg_filepath = os.path.join(OUTPUTS_DIR,writer,'images',filename,'.png')\n",
    "        shutil.copyfile(image_path, newimg_filepath)\n",
    "        \n",
    "        \n",
    "        newtext_filepath = os.path.join(OUTPUTS_DIR,writer,'labels',filename,'.txt')\n",
    "        file = open(newtext_filepath, 'w')\n",
    "        file.write(label_str)\n",
    "        file.close()\n",
    "\n",
    "        # Add stats \n",
    "        log[dam_type] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(OUTPUTS_DIR,'images'))\n",
    "os.mkdir(os.path.join(OUTPUTS_DIR,'labels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images_labels(png_folder, bbox_folder, classtype): \n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    Takes in folder of dam pngs, folder of bounding box json files\n",
    "    Normalizes json data to darknet format (center x, center y, bbox width, bbox height)\n",
    "    Creates new directories in darknet format\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for image_filename in os.listdir(png_folder):\n",
    "       \n",
    "        # read in image\n",
    "        img = mpimg.imread(os.path.join(png_folder,image_filename))\n",
    "\n",
    "        # get width and height\n",
    "        img_w = img.shape[0]\n",
    "        img_h = img.shape[1]\n",
    "\n",
    "        # get matching bounding box json file\n",
    "        json_filename = image_filename[:-4] + '.json'\n",
    "        json_filepath = os.path.join(bbox_folder, json_filename)\n",
    "        if not os.path.exists(json_filepath):\n",
    "            continue\n",
    "            #raise NameError(\"can't find bbox for %s\" % json_filename)\n",
    "            \n",
    "        # read json bounding box coordinates\n",
    "        with open(json_filepath) as json_file: \n",
    "            data = json.load(json_file)\n",
    "            coords = data['pixel_bounding_box']\n",
    "\n",
    "        # normalize to x-center, y-center, width, and height of bbox\n",
    "        avg_x = (coords[2] + coords[0]) / (2 * img_w)\n",
    "        avg_y = (coords[1] + coords[3]) / (2 * img_h)\n",
    "        nrm_w = (coords[2] - coords[0]) / img_w\n",
    "        nrm_h = (coords[1] - coords[3]) / img_h\n",
    "        nrm_xywh = np.array([avg_x, avg_y, nrm_w, nrm_h])\n",
    "\n",
    "        # create new folder for labels\n",
    "#         label_filename =\n",
    "#         shutil.copyfile(os.path.join(OUTPUTS_DIR,'labels',image_filename[:-4],'.txt'))\n",
    "\n",
    "        # write new label file and move to new folder\n",
    "        if classtype == 'dam':\n",
    "            label_str = '0 ' + str('%.6f'%nrm_xywh[0]) + ' ' + str('%.6f'%nrm_xywh[1]) + ' ' + str('%.6f'%nrm_xywh[2]) + ' ' + str('%.6f'%nrm_xywh[3])\n",
    "        else:\n",
    "            label_str = ''\n",
    "        \n",
    "        shutil.copyfile(json_filepath, '/labels' + json_filename[:-5] + '.txt')   \n",
    "        file = open(os.path.join(OUTPUTS_DIR, 'labels') + '/' + json_filename[:-5] + '.txt', 'w')\n",
    "        file.write(label_str)\n",
    "        file.close()\n",
    "\n",
    "        # move images to new folder\n",
    "        new_image_filepath = os.path.join('images', image_filename)\n",
    "        shutil.copyfile(png_folder + '/' + image_filename, os.path.join(OUTPUTS_DIR, new_image_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../storage/yolov3-m/dam_images/1656-1206_not_a_dam.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-41050fd1a046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNOT_A_DAM_IMAGE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_bb.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDAM_IMAGE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'not_a_dam_png_no_bbox'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../storage/yolov3-m/dam_images/1656-1206_not_a_dam.png'"
     ]
    }
   ],
   "source": [
    "# in progress\n",
    "\n",
    "# make directories for dam_png_no_bbox and not_a_dam_no_bbox\n",
    "#os.mkdir(os.path.join(OUTPUTS_DIR, 'dam_png_no_bbox'))\n",
    "for f in os.listdir(DAM_IMAGE_DIR):\n",
    "    if f.endswith('.png') and not f.endswith('_bb.png'):\n",
    "        shutil.copyfile(os.path.join(DAM_IMAGE_DIR, f), 'dam_png_no_bbox/'+f[:-4])\n",
    "#os.mkdir(os.path.join(OUTPUTS_DIR, 'not_a_dam_png_no_bbox'))\n",
    "for f in os.listdir(NOT_A_DAM_IMAGE_DIR):\n",
    "    if f.endswith('.png') and not f.endswith('_bb.png'):\n",
    "        shutil.copyfile(os.path.join(DAM_IMAGE_DIR, f), 'not_a_dam_png_no_bbox'+f[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: south africa set\n",
    "\n",
    "# make the test/train/validation/south africa splits\n",
    "\n",
    "# parameters\n",
    "# holdout_set_portion = 0.20\n",
    "validation_set_portion = 0.15\n",
    "test_set_portion = 0.30\n",
    "\n",
    "train_set = all_images_file_list.copy()\n",
    "\n",
    "south_africa_set = []\n",
    "\n",
    "# holdout_set = []\n",
    "# for i in range(int(holdout_set_portion * all_images_original_length):\n",
    "#     holdout_set.append(all_images_file_list_copy[i])\n",
    "#     all_images_file_list_copy.pop(i)\n",
    "\n",
    "validation_set = []\n",
    "for i in range(int(validation_set_portion * len(all_images_file_list))):\n",
    "    validation_set.append(train_set[i])\n",
    "    train_set.pop(i)\n",
    "\n",
    "test_set = []\n",
    "for i in range(int(test_set_portion * len(all_images_file_list))):\n",
    "    test_set.append(train_set[i])\n",
    "    train_set.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of validation set:\n",
      "16\n",
      "len of test set:\n",
      "32\n",
      "len of training set:\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "print('len of validation set:')\n",
    "print(len(validation_set))\n",
    "print('len of test set:')\n",
    "print(len(test_set))\n",
    "print('len of training set:')\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make json file directory\n",
    "#os.mkdir(os.path.join(OUTPUTS_DIR, 'json_file_directory'))\n",
    "\n",
    "JSON_FILE_DIR = os.path.join(OUTPUTS_DIR, 'json_file_directory')\n",
    "for f in os.listdir(DAM_IMAGE_DIR):\n",
    "    if f.endswith('.json'):\n",
    "        shutil.copyfile(os.path.join(DAM_IMAGE_DIR,f), os.path.join(JSON_FILE_DIR,f))\n",
    "for f in os.listdir(NOT_A_DAM_IMAGE_DIR):\n",
    "    if f.endswith('.json'):\n",
    "        shutil.copyfile(os.path.join(NOT_A_DAM_IMAGE_DIR,f), os.path.join(JSON_FILE_DIR,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['119497_clipped.json', '119453_clipped.json', '119455_clipped.json', '119484_clipped.json', '1656-1195_not_a_dam.json', '119472_clipped.json', '119489_clipped.json', '119402_clipped.json', '119490_clipped.json', '119429_clipped.json']\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(os.listdir(JSON_FILE_DIR)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images_labels(png_folder, bbox_folder, classtype): \n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    Takes in folder of dam pngs, folder of bounding box json files\n",
    "    Normalizes json data to darknet format (center x, center y, bbox width, bbox height)\n",
    "    Creates new directories in darknet format\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for image_filename in os.listdir(png_folder):\n",
    "       \n",
    "        # read in image\n",
    "        img = mpimg.imread(os.path.join(png_folder,image_filename))\n",
    "\n",
    "        # find width and height\n",
    "        img_w = img.shape[0]\n",
    "        img_h = img.shape[1]\n",
    "\n",
    "        # find matching bounding box json file\n",
    "        json_filename = image_filename[:-4] + '.json'\n",
    "        json_filepath = os.path.join(bbox_folder, json_filename)\n",
    "        if not os.path.exists(json_filepath):\n",
    "            continue\n",
    "            #raise NameError(\"can't find bbox for %s\" % json_filename)\n",
    "            \n",
    "        # read json bounding box coordinates\n",
    "        with open(json_filepath) as json_file: \n",
    "            data = json.load(json_file)\n",
    "            coords = data['pixel_bounding_box']\n",
    "\n",
    "        # normalize to x-center, y-center, width, and height of bbox\n",
    "        avg_x = (coords[2] + coords[0]) / (2 * img_w)\n",
    "        avg_y = (coords[1] + coords[3]) / (2 * img_h)\n",
    "        nrm_w = (coords[2] - coords[0]) / img_w\n",
    "        nrm_h = (coords[1] - coords[3]) / img_h\n",
    "        nrm_xywh = np.array([avg_x, avg_y, nrm_w, nrm_h])\n",
    "\n",
    "        # create new folder for labels\n",
    "#         label_filename =\n",
    "#         shutil.copyfile(os.path.join(OUTPUTS_DIR,'labels',image_filename[:-4],'.txt'))\n",
    "\n",
    "        # write new label file and move to new folder\n",
    "        if classtype == 'dam':\n",
    "            label_str = '0 ' + str('%.6f'%nrm_xywh[0]) + ' ' + str('%.6f'%nrm_xywh[1]) + ' ' + str('%.6f'%nrm_xywh[2]) + ' ' + str('%.6f'%nrm_xywh[3])\n",
    "        else:\n",
    "            label_str = ''\n",
    "        \n",
    "        shutil.copyfile(json_filepath, '/labels' + json_filename[:-5] + '.txt')   \n",
    "        file = open(os.path.join(OUTPUTS_DIR, 'labels') + '/' + json_filename[:-5] + '.txt', 'w')\n",
    "        file.write(label_str)\n",
    "        file.close()\n",
    "\n",
    "        # move images to new folder\n",
    "        new_image_filepath = os.path.join('images', image_filename)\n",
    "        shutil.copyfile(png_folder + '/' + image_filename, os.path.join(OUTPUTS_DIR, new_image_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot identify image file '../../storage/yolov3-m/dam_images/119453_clipped.png.aux.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-955f61b3a71c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create the image and label files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcreate_images_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDAM_IMAGE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJSON_FILE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcreate_images_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNOT_A_DAM_IMAGE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJSON_FILE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'not_dam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-c10499d8594b>\u001b[0m in \u001b[0;36mcreate_images_labels\u001b[0;34m(png_folder, bbox_folder, classtype)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# read in image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpng_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# find width and height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpilread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             raise ValueError('Only know how to handle extensions: %s; '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mpilread\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2588\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2590\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file '../../storage/yolov3-m/dam_images/119453_clipped.png.aux.xml'"
     ]
    }
   ],
   "source": [
    "# create the image and label files\n",
    "create_images_labels(DAM_IMAGE_DIR, JSON_FILE_DIR, 'dam')\n",
    "create_images_labels(NOT_A_DAM_IMAGE_DIR, JSON_FILE_DIR, 'not_dam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to move files of certain type to other folders\n",
    "\n",
    "def create_new_folder (src, dst, filetype):\n",
    "    \n",
    "    # create destination folder\n",
    "    os.mkdir(dst)\n",
    "    \n",
    "    # move files of specified format to destination folder\n",
    "    for filename in os.listdir(src):\n",
    "        if filename.endswith(filetype):\n",
    "            os.rename(src + '/' + filename, dst + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are four types of files in these folders: xml, png, png w/ bboxes, and json\n",
    "# darknet needs only the images (png) and the bbox labels (json)\n",
    "\n",
    "# move png files (not _bb.png files) to new folder\n",
    "create_new_folder('dam_images', 'dam_png', '.png') \n",
    "create_new_folder('dam_png', 'dam_bb_images', '_bb.png') \n",
    "create_new_folder('not_a_dam_images', 'not_a_dam_png', '.png') \n",
    "create_new_folder('not_a_dam_png', 'not_a_dam_bb_images', '_bb.png') \n",
    "\n",
    "# move json files to new folder\n",
    "create_new_folder('dam_images', 'dam_bboxes', '.json')\n",
    "create_new_folder('not_a_dam_images', 'not_a_dam_bboxes', '.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'filename'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images_labels(png_folder, bbox_folder, classtype): \n",
    "    \n",
    "    \"\"\" \n",
    "    Takes in folder of dam pngs, folder of bounding box json files\n",
    "    Normalizes json data to darknet format (center x, center y, bbox width, bbox height)\n",
    "    Creates new directories in darknet format\n",
    "    \"\"\"\n",
    "    \n",
    "    for image_filename in os.listdir(png_folder):\n",
    "       \n",
    "        # read in image\n",
    "        img = mpimg.imread(os.path.join(png_folder,image_filename))\n",
    "\n",
    "        # find width and height\n",
    "        img_w = img.shape[0]\n",
    "        img_h = img.shape[1]\n",
    "        \n",
    "        # find matching bounding box json file\n",
    "        json_filepath = os.path.join(bbox_folder,image_filename,'.json')\n",
    "        if not os.path.exists(json_filepath):\n",
    "            raise NameError(\"can't find bbox for %s'\" % image_filename)\n",
    "\n",
    "        # read json bounding box coordinates\n",
    "        with open(json_filepath) as json_file: \n",
    "            data = json.load(json_file)\n",
    "            coords = data['pixel_bounding_box']\n",
    "\n",
    "        # normalize to x-center, y-center, width, and height of bbox\n",
    "        avg_x = (coords[2] + coords[0]) / (2 * img_w)\n",
    "        avg_y = (coords[1] + coords[3]) / (2 * img_h)\n",
    "        nrm_w = (coords[2] - coords[0]) / img_w\n",
    "        nrm_h = (coords[1] - coords[3]) / img_h\n",
    "        nrm_xywh = np.array([avg_x, avg_y, nrm_w, nrm_h])\n",
    "\n",
    "        # create new folder for labels\n",
    "        shutil.copyfile(os.path.join(OUTPUTS_DIR,'labels',image_filename[:-4],'.txt'))\n",
    "\n",
    "        # write new label file and move to new folder\n",
    "        if classtype == 'dam':\n",
    "            label_str = '0 ' + str('%.6f'%nrm_xywh[0]) + ' ' + str('%.6f'%nrm_xywh[1]) + ' ' + str('%.6f'%nrm_xywh[2]) + ' ' + str('%.6f'%nrm_xywh[3])\n",
    "        else:\n",
    "            label_str = ''\n",
    "        shutil.copyfile(bbox_folder + '/' + bbox, 'labels/' + bbox[:-5] + '.txt')   \n",
    "        file = open('labels' + '/' + bbox[:-5] + '.txt', 'w')\n",
    "        file.write(label_str)\n",
    "        file.close()\n",
    "\n",
    "        # move images to new folder\n",
    "        shutil.copyfile(png_folder + '/' + image_filename, 'images/' + png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOS\n",
    "# X delete unwanted directories\n",
    "# - create test and train folders\n",
    "# - split test and train data into two folders\n",
    "# X create .txt files for test and train data file paths\n",
    "# X~ create .names file\n",
    "# X~ create .data file\n",
    "# X~ download cfg file\n",
    "# X download pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'shutil' has no attribute 'remove'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-94f619fae671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                  'not_a_dam_images', 'not_a_dam_png']\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdelete_folders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'shutil' has no attribute 'remove'"
     ]
    }
   ],
   "source": [
    "# delete unwanted directories\n",
    "delete_folders = ['dam_bb_images', 'dam_bboxes', 'dam_images', 'dam_png', 'not_a_dam_bb_images', 'not_a_dam_bboxes',\n",
    "                 'not_a_dam_images', 'not_a_dam_png']\n",
    "for folder in delete_folders:\n",
    "    shutil.rmtree(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create .txt files for test adn train data file paths\n",
    "\n",
    "def create_txt_file (split):\n",
    "    files = os.listdir('images/' + split)\n",
    "    cwd = os.getcwd()\n",
    "    txt = open(cwd + '/' + split + '_images.txt', 'w')\n",
    "    for file in files:\n",
    "        if file != '.ipynb_checkpoints':\n",
    "            txt.write(cwd + '/images/' + split + '/' + file + '\\n')\n",
    "    txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_txt_file('test')\n",
    "create_txt_file('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip files\n",
    "\n",
    "not_dams = zf.ZipFile('not_a_dam_images.zip', 'r')\n",
    "not_dams.extractall()\n",
    "not_dams.close()\n",
    "\n",
    "dams = zf.ZipFile('dam_images.zip', 'r')\n",
    "dams.extractall()\n",
    "dams.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
